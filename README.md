#### :part_alternation_mark: LLM performance 
How an LLM model can be evalauated?
- HellaSwag benchmark:
  - github [link](https://github.com/rowanz/hellaswag)

- Huggingface
  -  Open LLM Leaderboard ðŸ¤— [link](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) 
#### :page_facing_up: papers
Publication papers for LLM:
- Awesome-LLM: a curated list of Large Language Model [link](https://github.com/Hannibal046/Awesome-LLM)
